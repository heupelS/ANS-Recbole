Wed 10 Jul 2024 22:46:08 INFO  ['run_recbole.py', '--model=ANS', '--dataset=lastfm']
Wed 10 Jul 2024 22:46:08 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = dataset/lastfm
checkpoint_dir = saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 500
train_batch_size = 4096
learner = adam
learning_rate = 0.0001
train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 5, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}
eval_step = 8
stopping_step = 4
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}
repeatable = False
metrics = ['Recall', 'NDCG', 'MRR', 'Hit', 'Precision']
topk = [10, 20]
valid_metric = Recall@20
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 3

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = artist_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'artist_id']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = None
item_inter_num_interval = None
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
kg_reverse_r = False
entity_kg_num_interval = None
relation_kg_num_interval = None
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
plot_learning_curve = False
require_pow = False
enable_amp = False
enable_scaler = True
transform = None
train_after_converge = True
positive_sampling = True
model_name_custom = -
data_augmentation = False
Q = 5
K = 3
P = 20
embedding_size = 64
n_layers = 3
reg_weight = 0.001
eps = 0.35029810509314285
gamma = 0.1
numerical_features = []
discretization = None
MODEL_TYPE = ModelType.GENERAL
MODEL_INPUT_TYPE = InputType.PAIRWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


Wed 10 Jul 2024 22:46:08 INFO  lastfm
The number of users: 1893
Average actions of users: 49.06659619450317
The number of items: 17633
Average actions of items: 5.265086206896552
The number of inters: 92834
The sparsity of the dataset: 99.72188126708227%
Remain Fields: ['user_id', 'artist_id']
Wed 10 Jul 2024 22:46:08 INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 5, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]
Wed 10 Jul 2024 22:46:08 INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]
Wed 10 Jul 2024 22:46:10 INFO  ANS(
  (user_embedding): Embedding(1893, 64)
  (item_embedding): Embedding(17633, 64)
  (mf_loss): BPRLoss()
  (reg_loss): EmbLoss()
  (user_gate): Linear(in_features=64, out_features=64, bias=True)
  (item_gate): Linear(in_features=64, out_features=64, bias=True)
  (pos_gate): Linear(in_features=64, out_features=64, bias=True)
  (neg_gate): Linear(in_features=64, out_features=64, bias=True)
  (hard_gate): Linear(in_features=64, out_features=64, bias=True)
  (conf_gate): Linear(in_features=64, out_features=64, bias=True)
  (easy_gate): Linear(in_features=64, out_features=64, bias=True)
  (margin_model): Linear(in_features=64, out_features=1, bias=True)
)
Trainable parameters: 1278849
Wed 10 Jul 2024 22:46:10 INFO  FLOPs: 0.0
Wed 10 Jul 2024 22:46:14 INFO  epoch 0 training [time: 3.17s, train loss: 79.7400]
Wed 10 Jul 2024 22:46:17 INFO  epoch 1 training [time: 2.53s, train loss: 79.6840]
Wed 10 Jul 2024 22:46:19 INFO  epoch 2 training [time: 1.89s, train loss: 79.6420]
Wed 10 Jul 2024 22:46:21 INFO  epoch 3 training [time: 1.71s, train loss: 79.6060]
Wed 10 Jul 2024 22:46:22 INFO  epoch 4 training [time: 1.73s, train loss: 79.5725]
Wed 10 Jul 2024 22:46:24 INFO  epoch 5 training [time: 1.94s, train loss: 79.5418]
Wed 10 Jul 2024 22:46:26 INFO  epoch 6 training [time: 1.74s, train loss: 79.5107]
Wed 10 Jul 2024 22:46:28 INFO  epoch 7 training [time: 1.71s, train loss: 79.4775]
Wed 10 Jul 2024 22:46:30 INFO  epoch 7 evaluating [time: 2.44s, valid_score: 0.002000]
Wed 10 Jul 2024 22:46:30 INFO  valid result: 
recall@10 : 0.001    recall@20 : 0.002    ndcg@10 : 0.001    ndcg@20 : 0.002    mrr@10 : 0.002    mrr@20 : 0.003    hit@10 : 0.005    hit@20 : 0.012    precision@10 : 0.0    precision@20 : 0.001
Wed 10 Jul 2024 22:46:30 INFO  Saving current: saved/ANS-Jul-10-2024_22-46-10.pth
Wed 10 Jul 2024 22:46:32 INFO  epoch 8 training [time: 1.78s, train loss: 79.4410]
Wed 10 Jul 2024 22:46:34 INFO  epoch 9 training [time: 1.77s, train loss: 79.3973]
Wed 10 Jul 2024 22:46:36 INFO  epoch 10 training [time: 1.79s, train loss: 79.3400]
Wed 10 Jul 2024 22:46:37 INFO  epoch 11 training [time: 1.72s, train loss: 79.2568]
Wed 10 Jul 2024 22:46:39 INFO  epoch 12 training [time: 1.77s, train loss: 79.1223]
Wed 10 Jul 2024 22:46:41 INFO  epoch 13 training [time: 1.73s, train loss: 78.8748]
Wed 10 Jul 2024 22:46:43 INFO  epoch 14 training [time: 1.76s, train loss: 78.3526]
Wed 10 Jul 2024 22:46:44 INFO  epoch 15 training [time: 1.72s, train loss: 77.2045]
Wed 10 Jul 2024 22:46:46 INFO  epoch 15 evaluating [time: 2.27s, valid_score: 0.096000]
Wed 10 Jul 2024 22:46:46 INFO  valid result: 
recall@10 : 0.062    recall@20 : 0.096    ndcg@10 : 0.055    ndcg@20 : 0.069    mrr@10 : 0.105    mrr@20 : 0.111    hit@10 : 0.243    hit@20 : 0.337    precision@10 : 0.031    precision@20 : 0.024
Wed 10 Jul 2024 22:46:47 INFO  Saving current: saved/ANS-Jul-10-2024_22-46-10.pth
Wed 10 Jul 2024 22:46:48 INFO  epoch 16 training [time: 1.75s, train loss: 74.9882]
Wed 10 Jul 2024 22:46:50 INFO  epoch 17 training [time: 1.84s, train loss: 71.9252]
Wed 10 Jul 2024 22:46:52 INFO  epoch 18 training [time: 1.89s, train loss: 68.6615]
Wed 10 Jul 2024 22:46:54 INFO  epoch 19 training [time: 1.98s, train loss: 65.8594]
Wed 10 Jul 2024 22:46:56 INFO  epoch 20 training [time: 2.01s, train loss: 63.6683]
Wed 10 Jul 2024 22:46:58 INFO  epoch 21 training [time: 1.83s, train loss: 61.9138]
Wed 10 Jul 2024 22:47:00 INFO  epoch 22 training [time: 1.85s, train loss: 60.5134]
Wed 10 Jul 2024 22:47:01 INFO  epoch 23 training [time: 1.73s, train loss: 59.3613]
Wed 10 Jul 2024 22:47:04 INFO  epoch 23 evaluating [time: 2.29s, valid_score: 0.184000]
Wed 10 Jul 2024 22:47:04 INFO  valid result: 
recall@10 : 0.126    recall@20 : 0.184    ndcg@10 : 0.111    ndcg@20 : 0.136    mrr@10 : 0.197    mrr@20 : 0.205    hit@10 : 0.439    hit@20 : 0.549    precision@10 : 0.062    precision@20 : 0.045
Wed 10 Jul 2024 22:47:04 INFO  Saving current: saved/ANS-Jul-10-2024_22-46-10.pth
Wed 10 Jul 2024 22:47:06 INFO  epoch 24 training [time: 1.79s, train loss: 58.3065]
Wed 10 Jul 2024 22:47:07 INFO  epoch 25 training [time: 1.86s, train loss: 57.3177]
Wed 10 Jul 2024 22:47:09 INFO  epoch 26 training [time: 1.82s, train loss: 56.4350]
Wed 10 Jul 2024 22:47:11 INFO  epoch 27 training [time: 1.89s, train loss: 55.7101]
Wed 10 Jul 2024 22:47:13 INFO  epoch 28 training [time: 1.86s, train loss: 55.0287]
Wed 10 Jul 2024 22:47:15 INFO  epoch 29 training [time: 1.94s, train loss: 54.1640]
Wed 10 Jul 2024 22:47:17 INFO  epoch 30 training [time: 1.96s, train loss: 53.4002]
Wed 10 Jul 2024 22:47:19 INFO  epoch 31 training [time: 1.91s, train loss: 52.9207]
Wed 10 Jul 2024 22:47:21 INFO  epoch 31 evaluating [time: 2.30s, valid_score: 0.166000]
Wed 10 Jul 2024 22:47:21 INFO  valid result: 
recall@10 : 0.105    recall@20 : 0.166    ndcg@10 : 0.093    ndcg@20 : 0.119    mrr@10 : 0.175    mrr@20 : 0.185    hit@10 : 0.392    hit@20 : 0.536    precision@10 : 0.052    precision@20 : 0.041
Wed 10 Jul 2024 22:47:23 INFO  epoch 32 training [time: 1.83s, train loss: 52.2892]
Wed 10 Jul 2024 22:47:25 INFO  epoch 33 training [time: 1.86s, train loss: 51.7072]
Wed 10 Jul 2024 22:47:27 INFO  epoch 34 training [time: 1.84s, train loss: 51.1754]
Wed 10 Jul 2024 22:47:29 INFO  epoch 35 training [time: 1.98s, train loss: 50.5484]
Wed 10 Jul 2024 22:47:30 INFO  epoch 36 training [time: 1.82s, train loss: 49.9219]
Wed 10 Jul 2024 22:47:32 INFO  epoch 37 training [time: 1.99s, train loss: 49.6102]
Wed 10 Jul 2024 22:47:34 INFO  epoch 38 training [time: 2.02s, train loss: 49.2050]
Wed 10 Jul 2024 22:47:37 INFO  epoch 39 training [time: 2.24s, train loss: 48.5832]
Wed 10 Jul 2024 22:47:39 INFO  epoch 39 evaluating [time: 2.23s, valid_score: 0.163000]
Wed 10 Jul 2024 22:47:39 INFO  valid result: 
recall@10 : 0.101    recall@20 : 0.163    ndcg@10 : 0.087    ndcg@20 : 0.113    mrr@10 : 0.161    mrr@20 : 0.171    hit@10 : 0.386    hit@20 : 0.538    precision@10 : 0.05    precision@20 : 0.04
Wed 10 Jul 2024 22:47:41 INFO  epoch 40 training [time: 2.24s, train loss: 48.1610]
